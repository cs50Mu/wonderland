<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta name="description" content ="CS61A: Structure and Interpretation of Computer Programs" />
    <meta name="keywords" content ="CS61A, Computer Science, CS, 61A, Programming, John DeNero, Berkeley, EECS" />
    <meta name="author" content ="Andrew Huang, Rohin Shah, Jonathan Allen, Matthew Chow, Ajeya Cotra, Davis Foote, Jessica Gu, Angela Lin, Jeffrey Lu, Beth Marrone, Youri Park, Alana Tran, Dickson Tsai" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <link href="../../css/resource.css" rel="stylesheet" type="text/css">
<link href="../../css/project.css" rel="stylesheet" type="text/css">

    <title>Project 2: Twitter Trends | CS 61A Summer 2014</title>

  </head>
  <body style="font-family: Georgia,serif;">
    <h1 id="title-main">Project 2: Twitter Trends</h1>

    <div id='haiku'>
  
<blockquote><p><img src="images/texas.png" alt="Texas"></p>

<cite>
  What do people tweet?<br>
  Draw their feelings on a map <br>
  to discover <i>trends</i>
</cite></blockquote>

</div>

    <h2 id='table-of-contents'>Table of Contents</h2>
    <ul>
  <li><a href="trends.html#introduction">Introduction</a></li>
  <li><a href="trends.html#logistics">Logistics</a></li>
  <li><a href="trends.html#the-autograder">The Autograder</a></li>
  <li><a href="trends.html#phase-1-the-feelings-in-tweets">Phase 1: The Feelings in Tweets</a></li>
  <ul>
  <li><a href="trends.html#tweets">Tweets</a></li>
  <li><a href="trends.html#problem-1-1-pt">Problem 1 (1 pt)</a></li>
  <li><a href="trends.html#problem-2-2-pt">Problem 2 (2 pt)</a></li>
  <li><a href="trends.html#problem-3-1-pt">Problem 3 (1 pt)</a></li>
  <li><a href="trends.html#problem-4-1-pt">Problem 4 (1 pt)</a></li>
</ul>

  <li><a href="trends.html#phase-2-the-geometry-of-maps">Phase 2: The Geometry of Maps</a></li>
  <ul>
  <li><a href="trends.html#problem-5-2-pt">Problem 5 (2 pt)</a></li>
  <li><a href="trends.html#problem-6-1-pt">Problem 6 (1 pt)</a></li>
</ul>

  <li><a href="trends.html#phase-3-the-mood-of-the-nation">Phase 3: The Mood of the Nation</a></li>
  <ul>
  <li><a href="trends.html#problem-7-2-pt">Problem 7 (2 pt)</a></li>
  <li><a href="trends.html#problem-8-2-pt">Problem 8 (2 pt)</a></li>
</ul>

  <li><a href="trends.html#extensions">Extensions</a></li>
</ul>


    

<h2 id="introduction">Introduction</h2>

<p>In this project, you will develop a geographic visualization of Twitter
data across the USA. You will need to use lists and data
abstraction techniques to create a modular program. This project uses
ideas from Sections <a href="http://composingprograms.com/pages/21-introduction.html">2.1</a>, <a href="http://composingprograms.com/pages/22-data-abstraction.html">2.2</a>, and <a href="http://composingprograms.com/pages/23-sequences.html">2.3</a>, of the <a href="http://composingprograms.com">Composing Programs</a> online textbook.</p>

<p>The map displayed above depicts how the people in different states feel
about Texas.  This image is generated by:</p>

<ol>
  <li>Collecting public Twitter posts (tweets) that have been tagged with
  geographic locations and filtering for those that contain the
  "texas" query term,</li>
  <li>Assigning a sentiment (positive or negative) to each tweet, based on
  all of the words it contains,</li>
  <li>Aggregating tweets by the state with the closest geographic center,
  and finally</li>
  <li>Coloring each state according to the aggregate sentiment of its
  tweets.  Red means positive sentiment; blue means negative.</li>
</ol>

<p>The details of how to conduct each of these steps are contained within
the project description.  By the end of this project, you will be able
to map the sentiment of any word or phrase. The <a href="trends.zip">trends.zip</a> archive
contains all the starter code and a small set of data.</p>

<p>The project uses several files, but all of your changes will be made to
the first one.</p>

<table cellpadding="10" cellspacing="2">
  <tr>
    <td>
      <code>trends.py</code>
    </td>

    <td>
      A starter implementation of the main project file.
    </td>
  </tr>

  <tr>
    <td>
      <code>geo.py</code>
    </td>

    <td>
      Geographic positions, 2-D projection equations, and geographic
      distance functions.
    </td>
  </tr>

  <tr>
    <td>
      <code>database.py</code>
    </td>

    <td>
	  Functions for creating databases and interacting with them.
    </td>
  </tr>
  <tr>
    <td>
      <code>maps.py</code>
    </td>

    <td>
      Functions for drawing maps.
    </td>
  </tr>

  <tr>
    <td>
      <code>data.py</code>
    </td>

    <td>
      Functions for loading Twitter data from files.
    </td>
  </tr>

  <tr>
    <td>
      <code>graphics.py</code>
    </td>

    <td>
      A simple Python graphics library.
    </td>
  </tr>

  <tr>
    <td>
      <code>ucb.py</code>
    </td>

    <td>
      Utility functions for 61A.
    </td>
  </tr>

  <tr>
    <td><code>autograder.py</code></td>
    <td>Utility functions for grading.</td>
  </tr>
</table>

<p>The <a href="data">data</a> directory contains all the data files needed for the
project, and it's necessary to run the project. The <a href="trends.zip">trends.zip</a>
archive contains this directory: download it to get started.
Downloading each file individually is error-prone.</p>

<p>The autograder also uses a file called <a href="tests.pkl">tests.pkl</a>. This file is
included in the zip archive.</p>

<p>Finally, we have provided a <a href="trends.html#large-dataset">larger dataset</a> that you
can use once you are done with the project. See instructions at the end
of this document for ways to get the dataset.</p>


<h2 id="logistics">Logistics</h2>

<p>This is a one-week project with no partners.</p>

<p>Start early! Feel free to ask for help early and often. The course
staff is here to assist you, but we can't help everyone an hour before
the deadline. <a href="http://piazza.com/berkeley/summer2014/cs61a/home">Piazza</a> and the
<a href="http://chat.cs61a.org">IRC</a> awaits. You are not alone!</p>

<p>There are 15 possible points (12 for correctness and 3 for composition). You only
need to submit the file <code>trends.py</code>. You do not need to modify any
other files for this project. To submit the project, change to the
directory where the <code>trends.py</code> file is located and run <code>submit proj2</code>.</p>


<h2 id="the-autograder">The Autograder</h2>

<p>We've included an autograder which includes tests for each question.
Just as in the Hog project, you will have to unlock some of the tests
first before you can use them to test your project. To unlock tests for
a particular question, run the following command from your terminal:</p>

<pre><code>python3 autograder.py &#x2d;u q1</code></pre>

<p>Once you have unlocked the tests, you can
invoke autograder for a particular question as follows:</p>

<pre><code>python3 autograder.py &#x2d;q q1</code></pre>

<p>To help with debugging, you can also start an interactive prompt if
an error occurs by adding the <code>&#x2d;i</code> flag at the end:</p>

<pre><code>python3 autograder.py &#x2d;q q1 &#x2d;i</code></pre>

<p>You can also invoke the autograder for all problems at once using:</p>

<pre><code>python3 autograder.py</code></pre>

<p>One last note: you might have noticed a file called <code>tests.pkl</code> that
came with the project.  This file is used to store autograder tests, so
make sure <strong>not to modify it</strong>. If you need to get a fresh copy, you
can download it <a href="tests.pkl">here</a>.</p>


<h2 id="phase-1-the-feelings-in-tweets">Phase 1: The Feelings in Tweets</h2>

<p>In this phase, you will create an abstract data type for tweets, split
the text of a tweet into words, and calculate the amount of positive or
negative feeling in a tweet.</p>


<h3 id="tweets">Tweets</h3>

<p>First, we will define an abstract data type for tweets. To ensure that
we do not violate abstraction barriers later in the project, we will
create two different representations:</p>

<p>(A) The constructor <code>make_tweet</code> returns a Python list with
the following items:</p>

<ul>
  <li><strong>text</strong>: string, the text of the tweet, all in lowercase</li>
  <li><strong>time</strong>: datetime object, when the tweet was posted</li>
  <li><strong>latitude</strong>: a floating-point number, the latitude of the tweet's
  location</li>
  <li><strong>longitude</strong>: a floating-point number, the longitude of the tweet's
  location</li>
</ul>

<p>(B) The alternate constructor <code>make_tweet_fn</code> returns a function that
takes a string argument that is one of the keys above and returns the
corresponding value.</p>


<h3 id="problem-1-1-pt">Problem 1 (1 pt)</h3>

<p>Implement the missing selector and constructor functions for these two
representations: <code>tweet_text</code>, <code>tweet_time</code>, <code>tweet_location</code>
correspond to representation (A); <code>make_tweet_fn</code> corresponds to
representation (B).</p>

<p>For <code>tweet_location</code> you should return a <code>position</code> object. The
constructors and selectors for this abstract data type can be found in
<code>geo.py</code>. Remember to preserve data abstraction!</p>

<p>The two representations created by <code>make_tweet</code> and <code>make_tweet_fn</code> do
not need to work together, but each constructor should work with its
corresponding selectors.</p>

<p>As with project 1, you will need to unlock the tests first before using
them:</p>

<pre><code>python3 autograder.py &#x2d;u q1
python3 autograder.py &#x2d;q q1</code></pre>


<h3 id="problem-2-2-pt">Problem 2 (2 pt)</h3>

<p>Improve the <code>extract_words</code> function as follows:  Assume that a word is
any consecutive substring of <code>text</code> that consists only of ASCII
letters.  The string <code>ascii_letters</code> in the <code>string</code> module contains
all letters in the ASCII character set. The <code>extract_words</code> function
should list all such words in order and nothing else.</p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q2
python3 autograder.py &#x2d;q q2</code></pre>


<h3 id="problem-3-1-pt">Problem 3 (1 pt)</h3>

<p>Implement the <code>sentiment</code> abstract data type, which represents a
sentiment value that may or may not exist. The constructor
<code>make_sentiment</code> takes either a numeric value within the interval -1 to
1, or <code>None</code> to indicate that the value does not exist. Implement the
selectors <code>has_sentiment</code> and <code>sentiment_value</code> as well.  <em>You may use
any representation you choose, but the rest of your program should not
depend on this representation.</em></p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q3
python3 autograder.py &#x2d;q q3</code></pre>

<p>You can also call the <code>print_sentiment</code> function to print the sentiment
values of all sentiment-carrying words in a line of text.</p>

<pre><code>python3 trends.py &#x2d;p computer science is my favorite!
python3 trends.py &#x2d;p life without lambda: awful or awesome?</code></pre>


<h3 id="problem-4-1-pt">Problem 4 (1 pt)</h3>

<p>Implement <code>analyze_tweet_sentiment</code>, which takes a tweet (of the
abstract data type) and returns a <code>sentiment</code>.  Read the docstrings for
<code>get_word_sentiment</code> and <code>analyze_tweet_sentiment</code> in <code>trends.py</code> to
understand how the two functions interact. <em>Your implementation should
not depend on the representation of a sentiment!</em>.</p>

<p>The <code>tweet_words</code> function should prove useful here: it combines the
<code>tweet_text</code> selector and <code>extract_words</code> function from the previous
questions to return a list of words in a tweet.</p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q4
python3 autograder.py &#x2d;q q4</code></pre>


<h2 id="phase-2-the-geometry-of-maps">Phase 2: The Geometry of Maps</h2>

<p>In this phase, we will implement two functions that together determine
the centers of U.S. states. The shape of a state is represented as a
list of polygons.  Some states (e.g. Hawaii) consist of multiple
polygons, but most states (e.g. Colorado) consist of only one polygon
(still represented as a length-one list).</p>

<p>We will use the position abstract data type to represent geographic
latitude-longitude positions on the Earth. The data abstraction,
defined at the top of <code>geo.py</code>, has the constructor <code>make_position</code> and
the selectors <code>latitude</code> and <code>longitude</code>.</p>


<h3 id="problem-5-2-pt">Problem 5 (2 pt)</h3>

<p>Implement <code>find_centroid</code>, which takes a polygon and returns three
values: the coordinates of its centroid and its area.  The input
polygon is represented as a list of <code>position</code> values that are
consecutive vertices of its perimeter.  The first vertex is always
identical to the last.</p>

<p>The centroid of a two-dimensional shape is its center of balance,
defined as the intersection of all straight lines that evenly divide
the shape into equal-area halves.  <code>find_centroid</code> returns the centroid
and area of an individual polygon.</p>

<p>The formula for computing the <a href="http://en.wikipedia.org/wiki/Centroid#Centroid_of_polygon">centroid of a
polygon</a>
appears on Wikipedia. The formula relies on vertices being consecutive
(either clockwise or counterclockwise; both give the same answer), a
property that you may assume always holds for the input.</p>

<p><em>Hint</em>: latitudes correspond to the <code>x</code> values, and longitudes
correspond to the <code>y</code> values.</p>

<p>The area of a polygon is never negative.  Depending on how you compute
the area, you may need to use the built-in <code>abs</code> function to return a
non-negative number.</p>

<p>Manipulate positions using their selectors (<code>latitude</code> and <code>longitude</code>)
rather than assuming a particular representation.</p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q5
python3 autograder.py &#x2d;q q5</code></pre>


<h3 id="problem-6-1-pt">Problem 6 (1 pt)</h3>

<p>Implement <code>find_state_center</code>, which takes a state represented by a
list of polygons and returns a position <strong>object</strong>, its centroid.</p>

<p>The centroid of a collection of polygons can be computed by <a href="http://en.wikipedia.org/wiki/Centroid#By_geometric_decomposition">geometric
decomposition</a>
The centroid of a shape is the weighted average of the centroids of its
component polygons, weighted by their area.</p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q6
python3 autograder.py &#x2d;q q6</code></pre>

<p>Once you are finished, <code>draw_centered_map</code> will draw the <code>10</code> states
closest to a given state (including that state). A red dot should
appear over the two-letter postal code of the specified state.</p>

<pre><code>python3 trends.py &#x2d;d CA</code></pre>

<p>Your program should work identically, even if you use the functional
representation for tweets defined in question 1, using the -f flag.</p>

<pre><code>python3 trends.py &#x2d;f &#x2d;d CA</code></pre>


<h2 id="phase-3-the-mood-of-the-nation">Phase 3: The Mood of the Nation</h2>

<p>In this phase, you will group tweets by their nearest state center and
calculate the average positive or negative feeling in all the tweets
associated with a state.</p>

<p>The name <code>us_states</code> is bound to a database containing the shape of
each U.S. state, keyed by its two-letter postal code. You can use the
keys of this database to iterate over all the U.S. states.</p>

<p>A database is an abstract data type that we've created to store data.
Data is stored in a database as <em>key-value pairs</em>. Given a <em>key</em>, we
can access the <em>value</em> associated with that key from the database.
This is similar to indexing a list except databases are indexed with
keys, not numbers. Keys can be numbers or strings. Values can be
anything. Consider the following:</p>

<pre><code>&gt;&gt;&gt; database = make_database()
&gt;&gt;&gt; database = add_value(database, &quot;color&quot;, 25) 
&gt;&gt;&gt; database = add_value(database, 3, [1, &quot;cool&quot;]) 
&gt;&gt;&gt; get_keys(database)
[&quot;color&quot;, 3]
&gt;&gt;&gt; get_value_from_key(database, 3)
[1, &quot;cool&quot;]
&gt;&gt;&gt; get_len(database)
2
&gt;&gt;&gt; get_items(database)
[[&quot;color&quot;, 25], [3, [1, &quot;cool&quot;]]]</code></pre>

<p>The following are the constructors and selectors for databases:</p>

<ul>
  <li><code>make_database()</code>: creates a database</li>
  <li><code>add_value(database, key, value)</code>: creates a copy of that database and creates a mapping between that key and
  value in that new database and returns the new database. If the key already exists in the database, then
  we replace the previous key-value pair with the new key-value pair in the new database.</li>
  <li><code>get_keys(database)</code>: returns a list that contains all the keys found in that
  database</li>
  <li><code>get_values(database)</code>: returns a list that contains all the values found in
  that database</li>
  <li><code>get_value_from_key(database, key)</code>: returns the value associated with that
  key. It will raise an error if the key is not found in the database.</li>
  <li><code>get_len(database)</code>: returns the number of key-value pairs in the database</li>
  <li><code>get_items(database)</code>: returns a list of key-value pairs. Each key-value pair is represented as a list.</li>
</ul>


<h3 id="problem-7-2-pt">Problem 7 (2 pt)</h3>

<p>Implement <code>group_tweets_by_state</code>, which takes a sequence of tweets and
returns a database.  The keys of the returned database are state
names (two-letter postal codes), and the values are lists of tweets
that appear closer to that state's center than any other.</p>

<p>You should not include any states as keys that are not nearest to any
tweet.  You may want to define additional functions to organize your
implementation into modular components. You will need to use the
database of <code>us_states</code> described above.</p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q7
python3 autograder.py &#x2d;q q7</code></pre>


<h3 id="problem-8-2-pt">Problem 8 (2 pt)</h3>

<p>Implement <code>average_sentiments</code>. This function takes the database
returned by <code>group_tweets_by_state</code> and also returns a database.  The
keys of the returned database are the state names (two-letter postal
codes), and the values are average sentiment values for all the tweets
<strong>that have sentiment value</strong> in that state.</p>

<p>If a state has no tweets with sentiment values, leave it out of the
returned database entirely. Do not include a state with no sentiment
using a zero sentiment value. Zero represents neutral sentiment, not
unknown sentiment. States with unknown sentiment will appear gray,
while states with neutral sentiment will appear white.</p>

<p>Unlock, implement and test your implementation before moving on:</p>

<pre><code>python3 autograder.py &#x2d;u q8
python3 autograder.py &#x2d;q q8</code></pre>

<p>You should now be able to draw maps that are colored by sentiment
corresponding to tweets that contain a given term. The correct map for
Texas appears at the top of this page.</p>

<pre><code>python3 trends.py &#x2d;m texas
python3 trends.py &#x2d;m sandwich
python3 trends.py &#x2d;m obama
python3 trends.py &#x2d;m &quot;my life&quot;</code></pre>

<p>Your program should work identically, even if you use the functional
representation for tweets defined in question 1, using the -f flag.</p>

<pre><code>python3 trends.py &#x2d;f &#x2d;m texas</code></pre>

<p id='large-dataset'>
Finally, you can download a <a
href='http://www-inst.eecs.berkeley.edu/~cs61a/trends/all_tweets.zip'>larger dataset</a> once you are
done with your project. After extracting from the archive, you can move
<code>tweets2011.txt</code> and <code>tweets2014.txt</code> to the
`data` directory.
</p>

<p><strong>Warning</strong>: this dataset is 153 MB in zipped form. If you would rather
not download the files, you can copy your trends project onto your
<strong>class account</strong>, and do the following on your class account:</p>

<pre><code>cd trends/data
setup&#x2d;tweets</code></pre>

<p>If you run your project from your class account, make sure to use the
<code>&#x2d;X</code> with <code>ssh</code> (on Macs or Linux) or enable XMing (on Windows)!</p>

<p><strong>Note:</strong> as stated in the accompanying <code>README.txt</code>, the dataset is
intended solely for use with this project. Contents of <code>tweets2014.txt</code>
may not be redistributed or made public (e.g. on a version-control
repository).  After setting up the new tweets in your data directory,
You can then use the <code>&#x2d;m</code> flag above to search for more phrases, and
the <code>&#x2d;t</code> to specify the data file, like the following:</p>

<pre><code>python3 trends.py &#x2d;m christmas &#x2d;t tweets2011.txt
python3 trends.py &#x2d;m christmas &#x2d;t tweets2014.txt</code></pre>

<p><em>Congratulations!</em> One more 61A project completed.</p>


<h2 id="extensions">Extensions</h2>

<p>These extensions are optional and ungraded.  In this class, you are
welcome to program just for fun.  If you build something interesting,
come to office hours and give us a demo. However, please do not change
the behavior or signature of the functions you have already
implemented.</p>

<ul>
  <li>Implement a function <code>draw_map_by_hour</code> that visualizes the tweets
  that were posted during each hour of the day. For example, you'll
  discover that "sandwich" tweets appear most positive at 10:00pm: late
  night snack!</li>
  <li>Punctuation can be an indicator of sentiment as well.  Add an
  emoticon (smiley) detector that attributes positive sentiment to
  happy faces <code>:&#x2d;)</code> and negative sentiment to sad ones.</li>
  <li>In the standard implementation, some tweets are associated with
  different states than the ones in which they occurred.  For example,
  all tweets from Manhattan are assigned to New Jersey.  New Yorkers
  would be appalled! Write a function <code>find_containing_state</code> that
  finds the state that actually contains a tweet position.</li>
  <li>The <code>graphics.py</code> package supports animation.  Use the <code>slide_shape</code>
  method to have states and dots slide into place.</li>
  <li><a href="http://norvig.com/spell-correct.html">Correct the spelling</a> of
  tweets before you compute their sentiment.</li>
  <li>Calculate the total average sentiment of the whole country for a term
  and display that using the map.py and graphics.py package (try and
  understand the implementation of <code>draw_most_talkative_states</code> then
  use it as a foundation and modify as needed)</li>
</ul>

<p><strong>Acknowledgements:</strong> Aditi Muralidharan developed this project with
John DeNero. Hamilton Nguyen extended it. Keegan Mann developed the
autograder. Many others have contributed as well.</p>

  </body>

  
</html>
